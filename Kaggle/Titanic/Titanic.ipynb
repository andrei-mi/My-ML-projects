{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training and test datasets\n",
    "dataset = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering on Names column\n",
    "def title(name):\n",
    "    title_search = re.search('([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "def surname(name):\n",
    "    surname_search = re.search('([A-Za-z]+),', name)\n",
    "    if surname_search:\n",
    "        return surname_search.group(1)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Title'] = dataset['Name'].apply(title)\n",
    "dataset['Surname'] = dataset['Name'].apply(surname)\n",
    "\n",
    "dataset['Title'] = dataset['Title'].replace(['Don', 'Rev', 'Dr', 'Major', 'Lady', 'Sir', 'Col','Countess', 'Capt', 'Jonkheer'], 'Rare')\n",
    "dataset['Title'] = dataset['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "dataset['Title'] = dataset['Title'].replace(['Mme'], 'Mrs')\n",
    "\n",
    "data_test['Title'] = data_test['Name'].apply(title)\n",
    "data_test['Surname'] = data_test['Name'].apply(surname)\n",
    "\n",
    "data_test['Title'] = data_test['Title'].replace(['Dona','Don', 'Rev', 'Dr', 'Major', 'Lady', 'Sir', 'Col','Countess', 'Capt', 'Jonkheer'], 'Rare')\n",
    "data_test['Title'] = data_test['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "data_test['Title'] = data_test['Title'].replace(['Mme'], 'Mrs')\n",
    "\n",
    "\n",
    "\n",
    "X_train = dataset.drop(['Name', 'Cabin', 'Ticket', 'Age', 'Fare'], axis = 1)\n",
    "y_train = dataset['Survived']\n",
    "\n",
    "X_test = data_test.drop(['Name', 'Cabin', 'Ticket', 'Age', 'Fare'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ryerson\n",
      "64    956\n",
      "Name: PassengerId, dtype: int64\n",
      "Wells\n",
      "89    981\n",
      "Name: PassengerId, dtype: int64\n",
      "Touma\n",
      "161    1053\n",
      "Name: PassengerId, dtype: int64\n",
      "Drew\n",
      "194    1086\n",
      "Name: PassengerId, dtype: int64\n",
      "Spedden\n",
      "196    1088\n",
      "Name: PassengerId, dtype: int64\n",
      "Aks\n",
      "307    1199\n",
      "Name: PassengerId, dtype: int64\n",
      "Abbott\n",
      "392    1284\n",
      "Name: PassengerId, dtype: int64\n",
      "Peter\n",
      "417    1309\n",
      "Name: PassengerId, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Getting the list of boys in the test data and predicting their survival to be 1 in case all their female and boys\n",
    "#relatives in the training data have survived. in case there are no such relatives, we don't make any changes\n",
    "master_test = X_test.loc[X_test['Title'] == 'Master']\n",
    "\n",
    "y_pr = pd.Series(np.zeros(418) , index = range(892,1310))\n",
    "\n",
    "l1 = []\n",
    "for i in master_test['Surname']:\n",
    "     if len(X_train.loc[(X_train['Surname'] == i) & (X_train['Title'].isin(['Mrs', 'Miss', 'Master']))]['Survived']) > 0  and sum(X_train.loc[(X_train['Surname'] == i) & (X_train['Title'].isin(['Mrs', 'Miss', 'Master']))]['Survived']) == len(X_train.loc[(X_train['Surname'] == i) & (X_train['Title'].isin(['Mrs', 'Miss', 'Master']))]['Survived']):\n",
    "         print(i)\n",
    "         print(master_test.loc[master_test['Surname'] == i]['PassengerId'])\n",
    "         for j in range(len(master_test.loc[master_test['Surname'] == i].index)):\n",
    "             l1.append(master_test.loc[master_test['Surname'] == i].index[j])\n",
    "\n",
    "l1 = list(np.unique(np.sort(np.array(l1)))+892)\n",
    "\n",
    "\n",
    "y_pr[l1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ilmakangas\n",
      "18    910\n",
      "Name: PassengerId, dtype: int64\n",
      "Johnston\n",
      "33    925\n",
      "Name: PassengerId, dtype: int64\n",
      "Cacic\n",
      "37    929\n",
      "Name: PassengerId, dtype: int64\n",
      "Lefebre\n",
      "132    1024\n",
      "Name: PassengerId, dtype: int64\n",
      "Goodwin\n",
      "140    1032\n",
      "Name: PassengerId, dtype: int64\n",
      "Sage\n",
      "188    1080\n",
      "365    1257\n",
      "Name: PassengerId, dtype: int64\n",
      "Oreskovic\n",
      "280    1172\n",
      "Name: PassengerId, dtype: int64\n",
      "Rosblom\n",
      "284    1176\n",
      "Name: PassengerId, dtype: int64\n",
      "Sage\n",
      "188    1080\n",
      "365    1257\n",
      "Name: PassengerId, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Getting the PassengerId list of women in the test data and predicting their survival to be 0 in case all their female and boys\n",
    "#relatives in the training data died. in case there are no such relatives, we don't make any changes\n",
    "female_test = X_test.loc[X_test['Sex'] == 'female']\n",
    "\n",
    "l2 = []\n",
    "for i in female_test['Surname']:\n",
    "     if len(X_train.loc[(X_train['Surname'] == i) & (X_train['Title'].isin(['Mrs', 'Miss', 'Master']))]['Survived']) > 0  and sum(X_train.loc[(X_train['Surname'] == i) & (X_train['Title'].isin(['Mrs', 'Miss', 'Master']))]['Survived']) == 0:\n",
    "         print(i)\n",
    "         print(female_test.loc[female_test['Surname'] == i]['PassengerId'])\n",
    "         for j in range(len(female_test.loc[female_test['Surname'] == i].index)):\n",
    "             l2.append(female_test.loc[female_test['Surname'] == i].index[j])\n",
    "\n",
    "l2 = list(np.unique(np.sort(np.array(l2)))+892)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([dataset.drop('Survived', axis = 1), data_test])\n",
    "\n",
    "#Preparing training data\n",
    "all_data['Embarked'].fillna('S', inplace = True)\n",
    "all_data['Sex'] = all_data['Sex'].map({'female': 1, 'male': 0})\n",
    "all_data['Age'] = all_data['Age'].fillna(all_data['Age'].mean())\n",
    "all_data['Fare'] = all_data['Fare'].fillna(all_data['Fare'].mean())\n",
    "\n",
    "#Feature engineering \n",
    "bins = [0, 12, 18, 25, 60,all_data['Age'].max()]\n",
    "levels = ['child', 'teen', 'young', 'adult', 'elderly']\n",
    "all_data['Age Category'] = pd.cut(all_data.Age, bins, labels=levels)\n",
    "\n",
    "fare_bins = [0, 10, 20, 50, all_data['Fare'].max()]\n",
    "fare_levels = ['low', 'median', 'average', 'high']\n",
    "all_data['Fare_Category'] = pd.cut(all_data.Fare, fare_bins, labels=fare_levels)\n",
    "all_data['Fare_Category'] = all_data['Fare_Category'].fillna('low')\n",
    "\n",
    "\n",
    "X_train = all_data.drop(['Name', 'Cabin', 'Ticket', 'Age', 'Fare', 'PassengerId', 'Surname', 'Title'], axis = 1).values[:891,:]\n",
    "y_train = dataset['Survived'].values\n",
    "\n",
    "X_test = all_data.drop(['Name', 'Cabin', 'Ticket', 'Age', 'Fare', 'PassengerId', 'Surname', 'Title'], axis = 1).values[891:, :]\n",
    "\n",
    "\n",
    "df_train = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrei/anaconda3/envs/my_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/andrei/anaconda3/envs/my_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/home/andrei/anaconda3/envs/my_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/andrei/anaconda3/envs/my_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Dummy variables\n",
    "labelencoder_X = LabelEncoder()\n",
    "X_train[:,4] = labelencoder_X.fit_transform(X_train[:,4])\n",
    "X_train[:,5] = labelencoder_X.fit_transform(X_train[:,5])\n",
    "X_train[:,6] = labelencoder_X.fit_transform(X_train[:,6])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [4,5,6]) \n",
    "X_train = onehotencoder.fit_transform(X_train).toarray()\n",
    "\n",
    "labelencoder_X = LabelEncoder()\n",
    "X_test[:,4] = labelencoder_X.fit_transform(X_test[:,4])\n",
    "X_test[:,5] = labelencoder_X.fit_transform(X_test[:,5])\n",
    "X_test[:,6] = labelencoder_X.fit_transform(X_test[:,6])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [4,5,6]) \n",
    "X_test = onehotencoder.fit_transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrei/anaconda3/envs/my_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "0.8294051627384961\n",
      "SVC(C=200, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 280 out of 280 | elapsed:   27.7s finished\n"
     ]
    }
   ],
   "source": [
    "#SVC\n",
    "#Fitting Kernel SVC to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Test set results\n",
    "y_pred = pd.Series(classifier.predict(X_test))\n",
    "\n",
    "#Output results\n",
    "results = pd.concat([data_test['PassengerId'], y_pred], axis = 1)\n",
    "results.to_csv('Titanic_my_SVC_predictions.csv')\n",
    "\n",
    "\n",
    "#Best score yet on kaggle: 0.808\n",
    "#Parameter tuning\n",
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "param_grid = {'kernel': ['rbf','linear'],\n",
    "              'gamma' : [0.001, 0.01, 0.1, 1],\n",
    "              'C': [1,10,50,100,200,500,1000]}\n",
    "model_svc = GridSearchCV(model, param_grid = param_grid, cv = 5, scoring = \"accuracy\", n_jobs = 4, verbose = 1)\n",
    "model_svc.fit(X_train, y_train)\n",
    "\n",
    "#best estimate\n",
    "print(model_svc.best_score_)\n",
    "\n",
    "#best estimator\n",
    "print(model_svc.best_estimator_)\n",
    "\n",
    "classifier = model_svc.best_estimator_\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predict the test set results\n",
    "y_pred = pd.Series(classifier.predict(X_test), index = range(892,1310))\n",
    "\n",
    "y_pred[l1] = 1\n",
    "y_pred[l2] = 0\n",
    "\n",
    "#Output results\n",
    "results = np.vstack([data_test['PassengerId'].values, y_pred.values]).T\n",
    "submission = pd.DataFrame(results, columns = ['PassengerId', 'Survived'])\n",
    "submission.to_csv('Titanic_my_tuned_SVC-GM_predictions_09.12.2019.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
