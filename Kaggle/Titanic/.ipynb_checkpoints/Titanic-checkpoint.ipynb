{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training and test datasets\n",
    "dataset = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering on Names column\n",
    "def title(name):\n",
    "    title_search = re.search('([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "def surname(name):\n",
    "    surname_search = re.search('([A-Za-z]+),', name)\n",
    "    if surname_search:\n",
    "        return surname_search.group(1)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Title'] = dataset['Name'].apply(title)\n",
    "dataset['Surname'] = dataset['Name'].apply(surname)\n",
    "\n",
    "dataset['Title'] = dataset['Title'].replace(['Don', 'Rev', 'Dr', 'Major', 'Lady', 'Sir', 'Col','Countess', 'Capt', 'Jonkheer'], 'Rare')\n",
    "dataset['Title'] = dataset['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "dataset['Title'] = dataset['Title'].replace(['Mme'], 'Mrs')\n",
    "\n",
    "data_test['Title'] = data_test['Name'].apply(title)\n",
    "data_test['Surname'] = data_test['Name'].apply(surname)\n",
    "\n",
    "data_test['Title'] = data_test['Title'].replace(['Dona','Don', 'Rev', 'Dr', 'Major', 'Lady', 'Sir', 'Col','Countess', 'Capt', 'Jonkheer'], 'Rare')\n",
    "data_test['Title'] = data_test['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "data_test['Title'] = data_test['Title'].replace(['Mme'], 'Mrs')\n",
    "\n",
    "\n",
    "\n",
    "X_train = dataset.drop(['Name', 'Cabin', 'Ticket', 'Age', 'Fare'], axis = 1)\n",
    "y_train = dataset['Survived']\n",
    "\n",
    "X_test = data_test.drop(['Name', 'Cabin', 'Ticket', 'Age', 'Fare'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ryerson\n",
      "64    956\n",
      "Name: PassengerId, dtype: int64\n",
      "Wells\n",
      "89    981\n",
      "Name: PassengerId, dtype: int64\n",
      "Touma\n",
      "161    1053\n",
      "Name: PassengerId, dtype: int64\n",
      "Drew\n",
      "194    1086\n",
      "Name: PassengerId, dtype: int64\n",
      "Spedden\n",
      "196    1088\n",
      "Name: PassengerId, dtype: int64\n",
      "Aks\n",
      "307    1199\n",
      "Name: PassengerId, dtype: int64\n",
      "Abbott\n",
      "392    1284\n",
      "Name: PassengerId, dtype: int64\n",
      "Peter\n",
      "417    1309\n",
      "Name: PassengerId, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Getting the list of boys in the test data and predicting their survival to be 1 in case all their female and boys\n",
    "#relatives in the training data have survived. in case there are no such relatives, we don't make any changes\n",
    "master_test = X_test.loc[X_test['Title'] == 'Master']\n",
    "\n",
    "y_pr = pd.Series(np.zeros(418) , index = range(892,1310))\n",
    "\n",
    "l1 = []\n",
    "for i in master_test['Surname']:\n",
    "     if len(X_train.loc[(X_train['Surname'] == i) & (X_train['Title'].isin(['Mrs', 'Miss', 'Master']))]['Survived']) > 0  and sum(X_train.loc[(X_train['Surname'] == i) & (X_train['Title'].isin(['Mrs', 'Miss', 'Master']))]['Survived']) == len(X_train.loc[(X_train['Surname'] == i) & (X_train['Title'].isin(['Mrs', 'Miss', 'Master']))]['Survived']):\n",
    "         print(i)\n",
    "         print(master_test.loc[master_test['Surname'] == i]['PassengerId'])\n",
    "         for j in range(len(master_test.loc[master_test['Surname'] == i].index)):\n",
    "             l1.append(master_test.loc[master_test['Surname'] == i].index[j])\n",
    "\n",
    "l1 = list(np.unique(np.sort(np.array(l1)))+892)\n",
    "\n",
    "\n",
    "y_pr[l1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ilmakangas\n",
      "18    910\n",
      "Name: PassengerId, dtype: int64\n",
      "Johnston\n",
      "33    925\n",
      "Name: PassengerId, dtype: int64\n",
      "Cacic\n",
      "37    929\n",
      "Name: PassengerId, dtype: int64\n",
      "Lefebre\n",
      "132    1024\n",
      "Name: PassengerId, dtype: int64\n",
      "Goodwin\n",
      "140    1032\n",
      "Name: PassengerId, dtype: int64\n",
      "Sage\n",
      "188    1080\n",
      "365    1257\n",
      "Name: PassengerId, dtype: int64\n",
      "Oreskovic\n",
      "280    1172\n",
      "Name: PassengerId, dtype: int64\n",
      "Rosblom\n",
      "284    1176\n",
      "Name: PassengerId, dtype: int64\n",
      "Sage\n",
      "188    1080\n",
      "365    1257\n",
      "Name: PassengerId, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Getting the PassengerId list of women in the test data and predicting their survival to be 0 in case all their female and boys\n",
    "#relatives in the training data died. in case there are no such relatives, we don't make any changes\n",
    "female_test = X_test.loc[X_test['Sex'] == 'female']\n",
    "\n",
    "l2 = []\n",
    "for i in female_test['Surname']:\n",
    "     if len(X_train.loc[(X_train['Surname'] == i) & (X_train['Title'].isin(['Mrs', 'Miss', 'Master']))]['Survived']) > 0  and sum(X_train.loc[(X_train['Surname'] == i) & (X_train['Title'].isin(['Mrs', 'Miss', 'Master']))]['Survived']) == 0:\n",
    "         print(i)\n",
    "         print(female_test.loc[female_test['Surname'] == i]['PassengerId'])\n",
    "         for j in range(len(female_test.loc[female_test['Surname'] == i].index)):\n",
    "             l2.append(female_test.loc[female_test['Surname'] == i].index[j])\n",
    "\n",
    "l2 = list(np.unique(np.sort(np.array(l2)))+892)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([dataset.drop('Survived', axis = 1), data_test])\n",
    "\n",
    "#Preparing training data\n",
    "all_data['Embarked'].fillna('S', inplace = True)\n",
    "all_data['Sex'] = all_data['Sex'].map({'female': 1, 'male': 0})\n",
    "all_data['Age'] = all_data['Age'].fillna(all_data['Age'].mean())\n",
    "all_data['Fare'] = all_data['Fare'].fillna(all_data['Fare'].mean())\n",
    "\n",
    "#Feature engineering \n",
    "bins = [0, 12, 18, 25, 60,all_data['Age'].max()]\n",
    "levels = ['child', 'teen', 'young', 'adult', 'elderly']\n",
    "all_data['Age Category'] = pd.cut(all_data.Age, bins, labels=levels)\n",
    "\n",
    "fare_bins = [0, 10, 20, 50, all_data['Fare'].max()]\n",
    "fare_levels = ['low', 'median', 'average', 'high']\n",
    "all_data['Fare_Category'] = pd.cut(all_data.Fare, fare_bins, labels=fare_levels)\n",
    "all_data['Fare_Category'] = all_data['Fare_Category'].fillna('low')\n",
    "\n",
    "\n",
    "X_train = all_data.drop(['Name', 'Cabin', 'Ticket', 'Age', 'Fare', 'PassengerId', 'Surname', 'Title'], axis = 1).values[:891,:]\n",
    "y_train = dataset['Survived'].values\n",
    "\n",
    "X_test = all_data.drop(['Name', 'Cabin', 'Ticket', 'Age', 'Fare', 'PassengerId', 'Surname', 'Title'], axis = 1).values[891:, :]\n",
    "\n",
    "\n",
    "df_train = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [4,5,6])], remainder='passthrough')\n",
    "X_train = np.array(columnTransformer.fit_transform(X_train), dtype = np.str)\n",
    "X_test = np.array(columnTransformer.fit_transform(X_test), dtype = np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrei/anaconda3/envs/my_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 134 tasks      | elapsed:    2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8294051627384961\n",
      "SVC(C=200, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 280 out of 280 | elapsed:   17.4s finished\n"
     ]
    }
   ],
   "source": [
    "#Best score yet on kaggle: 0.808\n",
    "#Parameter tuning for SVC\n",
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "param_grid = {'kernel': ['rbf','linear'],\n",
    "              'gamma' : [0.001, 0.01, 0.1, 1],\n",
    "              'C': [1,10,50,100,200,500,1000]}\n",
    "model_svc = GridSearchCV(model, param_grid = param_grid, cv = 5, scoring = \"accuracy\", n_jobs = 4, verbose = 1)\n",
    "model_svc.fit(X_train, y_train)\n",
    "\n",
    "#best estimate\n",
    "print(model_svc.best_score_)\n",
    "\n",
    "#best estimator\n",
    "print(model_svc.best_estimator_)\n",
    "\n",
    "classifier = model_svc.best_estimator_\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predict the test set results\n",
    "y_pred = pd.Series(classifier.predict(X_test), index = range(892,1310))\n",
    "\n",
    "y_pred[l1] = 1\n",
    "y_pred[l2] = 0\n",
    "\n",
    "#Output results\n",
    "results = np.vstack([data_test['PassengerId'].values, y_pred.values]).T\n",
    "submission = pd.DataFrame(results, columns = ['PassengerId', 'Survived'])\n",
    "submission.to_csv(r'Titanic_my_tuned_SVC-GM_predictions.csv' , index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
